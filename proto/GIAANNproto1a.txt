DONE//do:
GPT4o prompt 1a1a;
Please create an abstract biological neural neural network simulation for natural language processing in python. 
- Use the pytorch API for hardware acceleration of all arrays (for efficient parallel processing of connectivity). Do not initialise the array with a predetermined dictionary; dynamically populate the arrays as new dictionary words and relations are encountered. Will be discussed below.
- Use vector graphics library such as networkx to always maintain a complete visualisation of the network (including active neurons). Only draw the parts of the network that are not empty.
- The application continuously reads sentences from a large textual corpus from huggingface (such as a Wikpedia dataset). Please use the library nltk.
- It identifies all possible POS (parts of speech) tags of each word in a sentence. Some words may have more than one possible POS tag. Please use the library spacy. 
- Each word is stored in a unique column (dictionary of columns for each word in dataset). Maintain an array of n column, each of size y, where y is the number of neurons per column. 
- Each column represents a unique concept. Columns which represent identical concepts can be merged at a later time; we will ignore column merging for now (such as "next_to" and "near"). We will also ignore the fact words can have multiple meanings for now (i.e. words can represent independent concepts).
- The columns represent general concepts, but they can also represent more specific concepts or instances by incorporating relations, such as actions (verbs) and conditions (prepositions). Examples of action relations (verbs) include "run" or eat. Examples of conditional relations (prepositions) include "near" or "above. The relations are each assigned a unique relation neuron (verb or preposition), and are connected to any number of target concept nouns (in separate columns); e.g. "bone", "to" etc
- The columns typically represent substances (or nouns), but they can also represent actions or conditions (verbs or prepositions). Only in the case of multiword prepositions (e.g. "next to") or multiword verbs (i.e. phrasal verb) (e.g. "look up") do action and condition columns have relations; e.g. "to" in "run to the park"
- determiners are ignored for now ("the", "a" etc)
- It should be noted that to properly connect relation nodes to their concept (subject) and their target (object), an advanced natural language processor is used. Since we are simulating the creation of an abstract biological neural network, we will implement our own custom learning algorithm for associating (connecting) these nodes. Since we do not have a syntactical breakdown of sentences, we will infer that any verb/preposition that occurs after a noun word (or directly after another verb/preposition word) in a sentence is possibly connected to that word. The closer they occur, the more likely they are to be connected, but this is not necessarily the case. Consider the example; "the cat that ate the mouse ran to the park": in this example "ran" and "ate" are directly connected to "cat", "ran" is not directly connected to "mouse" despite being nearest to it. Therefore, we will temporarily connect every following word to each word in the sentence. You should be aware this this will generate a set of word associations for each concept word similar to the historic NLP algorithms like co-occurance matrix or word2vec. For now just instantiate every possible relation neuron for every concept neuron in the sentence.
- This is the specificiation for now; please generate all necessary code to run the abstract biological neural network simulation. I should visualise the complete graph every time a new sentence is parsed by the application. Pause the simulation after every sentence, and except any key to continue the simulation. Let the user exit the simulation at any sentence by pressing Ctrl-D.
