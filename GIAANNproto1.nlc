//GIAANNpy Specification (prompts):

---
v1b (o1-preview):
Please create an abstract biological neural neural network simulation for natural language processing in python. This is the specification:
- Use the pytorch API for hardware acceleration of all arrays (for efficient parallel processing of connectivity). Do not initialise the array with a predetermined dictionary; dynamically populate the arrays as new dictionary words and relations are encountered. Will be discussed below.
- Use vector graphics library such as networkx to always maintain a complete visualisation of the network (including active neurons). Only draw the parts of the network that are not empty.
- The application continuously reads sequences (i.e. sentences) from a large textual corpus from huggingface (using a streamed Wikipedia dataset). Please use the library nltk.
- It identifies all possible POS (parts of speech) tags of each word in a sequence. Some words may have more than one possible POS tag. Please use the library spacy. 
- Perform lemmatisation of each word in sentence before processing it in the neural network. Use a suitable python library, e.g. spacy. Assign concept columns to lemmas not words. Assign feature neurons to words not lemmas.
- Maintain a boolean (useInference), and disable useInference mode. Maintain a boolean (lowMem), and enable lowMem mode. lowMem can only be used when useInference is disabled. It constrains the memory/computational processing of the network. 
- Maintain a boolean (usePOS), enable usePOS mode. If usePOS is enabled, a validity check of every lemma/word processed is performed to check its POS value. We will only assign unique concept columns for nouns that exist in this dictionary (always check POS). We will only assign feature neurons for non-nouns in this dictionary (always check POS). Nouns and non-nouns are detected using an English dictionary. Obtain lists of nouns and non-nouns using the nltk wordnet library.
- Every valid unique sequence lemma processed in the dataset is assigned a unique column in the network. Add these lemmas as keys in a concept columns dictionary (of dynamic size c). If usePOS is enabled, the validity check is peformed to check if the lemma is a noun before assigning a unique concept column. If usePOS is enabled and lowMem is disabled, set the size of the feature arrays (f) to the maximum number of non-nouns in an English dictionary.
- Every valid unique sequence lemma processed in the current sequence (not dataset) is assigned an observed column object. Add the lemmas as keys in an observed columns dictionary. Add the observed columns objects as values in this observed columns dictionary. The observed columns dictionary along with its observed column objects are refreshed every time a new sequence is processed, however the dataset concept columns dictionary is maintained. 
- Create a class defining observed columns. The observed column class contains an index to the dataset concept column dictionary. The observed column class contains a list of feature connection arrays. The observed column class also contains a list of feature neuron arrays when useLowMem mode is enabled. The reason connection data must be stored in observed columns is because they are large arrays and every column's connections cannot be stored in RAM simultaneously.
- If lowMem is enabled, the observed columns contain a list of arrays (pytorch) of f feature neurons, where f is the maximum number of feature neurons per column. If lowMem is disabled, create a global list of 2D arrays (pytorch) of c * f feature neurons, where c is the current number of concept columns, and where f is the maximum number of feature neurons per column. Create arrays for neuron strength, neuron permanence, and neuron activation (added to the list). The first feature neuron in the feature array (for each column) is always the concept neuron of the column (regardless of its name or POS). Note, feature neurons are combined in various combinations to represent different instances of a concept (or a specific concept thereof).
- Each column represents a unique concept. Columns (lemmas) can also represent similar concepts (synonyms), but we will ignore semantically similar words for now. We will also ignore the fact words can have multiple meanings for now (i.e. words can represent independent concepts). In this case particular columns will be semantically overloaded (polysemes/homographs).
- If usePOS is disabled, and if a column detects too many unique proximal features during training, it is likely that the column represents a common word (such as a definite/indefinite article) and will either a) be discarded or b) will not reliably contribute to next word predictions (as a consequence of the way in which connection weights are normalised by the number of feature neurons in a column). After training, the only columns to perform reliable predictions will be those representing concepts (typically substances/nouns). 
- The columns represent general concepts (via the activation of their concept neuron), but they can also represent more specific concepts or instances by incorporating/activating feature neurons. Feature neurons are used to define instances of concepts. There are different classes of feature neurons, including relations such as actions/verbs and conditions/prepositions, qualities/adjectives, or modifiers/adverbs, etc. We are will not be concerned about the specific classes of feature neurons for now; their distinct connectivity should emerge out of the training dynamics of the network.
- The column concepts typically represent substances (nouns), but they can also represent actions or conditions (verbs or prepositions). When usePOS is enabled, column concepts are restricted to substances (nouns). When usePOS is disabled, they assigned for every new lemma encountered in the dataset sequence. 
- For every concept word (lemma) i in the sequence, identify every feature neuron in that column that occurs q words before or after the concept word in the sequence, including the concept neuron. Note that this is similar to the bag of words algorithm. Increment the corresponding (i.e. contextual) elements (q) of the strength feature neuron array of each sequence word (i) observed concept column object. If a feature neuron has been encountered by a concept column its integer strength value will still be incremented.
- Create column internal and external connections. Connect these feature neurons to each other. Connect these feature neurons to every other identified feature neuron (observed in the current sequence) in every other concept column in the sequence. Connections are made by incrementing an integer strength value in a connection array (initialised as 0). If a connection has already been made this integer strength value will still be incremented.
- Store all connections for each source column in a list of integer 3D feature connection arrays, each of size f * c * f, where c is the length of the dictionary of columns, and f is the maximum number of feature neurons. The list of feature connection arrays includes a connection strength array (pytorch), connection permanence array, and connection activation array. The direction of a connection created corresponds to the word order of the features in the sequence. The lists of connection arrays are stored in the observed column class objects when in RAM.
- If usePOS is disabled, set q to 5. If usePOS is enabled, set q to the distance to the previous/next noun - 1 (depending on whether the feature selected is before or after the current concept word in the sequence). Always ensure the feature neuron selected is not out of bounds of the sequence. The closer the words occur in a sentence, the more likely they are to be connected, but this is not always the case. Consider an example of an exception; "the cat that ate the mouse ran to the park": in this example "ran" and "ate" are directly connected to "cat", "ran" is not directly connected to "mouse" despite being nearest to it.
- You should be aware this this will generate a large set of word associations for each concept word similar to historic NLP algorithms like the word co-occurance matrix.
- Generate all necessary code to run the abstract biological neural network simulation. Visualise the complete graph every time a new sentence is parsed by the application.
- The columns should be visualised along the horizontal x axis (they should each be a tall rectangle). Each concept word neuron should be stored at the bottom of each column. The other feature neurons should be stored along the vertical y axis of each column, above the concept neurons. Draw the connections between all feature neurons and their targets.  
- Please draw separate rectangles for each concept column. The concept column rectangles need to be drawn around the contents (concept and feature neurons) of each column. Ensure the neuron sizes are too large to be encapsulated by the rectangles and all the neurons (including the relation neurons) are drawin within the column rectangles.
- Print each sentence in the command line.
- Draw the concept neurons blue, and all other feature neurons in cyan.
- Draw all column internal feature connections in yellow, and all column external feature connections in orange. Remember that column internal feature connections and column external feature connections can be identified by their index in the connections array.
- Observed column object data are brought in/out of RAM from disk on demand. They are brought into RAM from disk for every column word in the sequence, and are saved back to disk after processing every sequence. This includes all array data within the list of feature connection arrays (and all array data within the list of feature neurons arrays if lowMem mode is enabled). If lowMem mode is enabled, global feature neurons arrays are brought in/out of RAM from disk before/after processing every sequence.
- The observed column object data and arrays are only brought into RAM after all new unique columns have been detected in the current sequence. These are added to the dataset concept columns dictionary. When the arrays are brought into RAM; if the concept columns dictionary has increased since the processing of the last sequence, the array rows will be expanded to accommodate the new concept columns (with all new rows properly initialised to their default value). If usePOS mode is disabled, the connection array columns will also be expanded to accommodate the new concept columns.
- The concept columns dictionary is also saved to disk after every sentence. When useInference is enabled, the concept columns dictionary is loaded from disk during startup, before processing the first sequence in the dataset.
- When writing the code, add the specification text to comments.
- When writing the code, always add complete code for all modes; do not skip code for disabled modes.
- Place the main processing loop in a separate function (i.e. "for article in dataset:"). Likewise, place every for loop and if statement within the second level of the main processing loop in a separate function (i.e. place every for loop and if statement at the second lowest nesting depth, directly within "for sentence in sentences:" in a separate function).
- Every feature neuron in a concept column has an integer permanence value (initialised as z1=3). A feature neuron's permanence integer is increased by a function zf every time the feature column neuron is activated by a sequence with that particular feature neuron being activated. A feature neuron's permanence integer is decreased by z2 (set to 1) every time the concept column neuron is activated by a sentence without that particular feature neuron being activated. If a feature neuron's permanence decreases to 0, then the feature neuron is removed from the column and it will no longer be visualised. 
- Likewise, store a permanence value for every feature connection, using the same permanence rules used for feature neurons.
- Every time a feature neuron or connection's permanence is increased (assuming the feature neuron or connection already exists), it exponentially increases its permanence from its current value (via the function zf). Set zf to a squared function of its current integer permanence value. All permanence values are intialised to z1 (3), but do not square them when they are first initialised. Permanence still decreases linearly every time a concept column is activated by the current word but the connection or neuron within it is not referenced by the sequence (-1). The higher the permanence the stronger the weight for next word prediction. We are ignoring next word prediction for now, which involves an iterative topk selection of most activated neurons/columns (similar to hopfield networks).
- Set an integer activation trace for every neuron and connection in the network. A feature neuron or connection is temporarily excited (set an activation trace value of +1) every time it is referenced by a word in a sequence. This temporary excitation lasts for j1=5 sequences before being removed (set an activation trace value of 0), unless it is activated by another sequence in the meantime. If it is activated by another sequence in the meantime, its activation trace is not modified (keep an activation trace value of +1), but overwrite this value in the code (set an activation trace value of +1) in case an implementation change is introduced in the future. The higher the activation trace the stronger the weight for next word prediction. We are not implementing next word prediction yet.
FUTURE; - Create a wrapper function called prediction for when useInference mode is enabled, and a wrapper function called training for when useInference mode is disabled. Prediction is similar to training, however the neuron/connection strengths and permanences are never modified (only the activation trace is modified). After processing x seed words in the sequence data (where x=5), the network continues to predict the next most active concept columns in the network. It compares its topk column predictions (set k=1) to the actual words in the sequence data. The observed column object data (i.e. list of feature connection arrays) for the topk predicted columns are brought into RAM after each topk column prediction, and removed from RAM after the next set of topk column predictions. When a concept column has been predicted, the connections of all of its active feature neurons are then activated, to calculate the next topk column predictions. If a concept column has previously been activated in the dataset, its activation trace may positively bias the current topk column selection (depending on the length of time from its last activation). 
CHATONLY/MANUAL; - If usePOS is disabled, set q to 5. If usePOS is enabled, set q to the distance to the previous/next noun - 1 (depending on whether the feature selected is before or after the current concept word in the sequence). Always ensure the feature neuron selected is not out of bounds of the sequence.
CHATONLY; - Expand all the observed column feature connection arrays by 1 dimension (from 2D to 3D) to be each of size f * c * f, where c is the length of the dictionary of columns, and f is the maximum number of feature neurons per column. Update the existing feature connection code; feature neurons are connected to every other identified feature neuron (observed in the current sequence) in every other concept column in the sequence.
MANUAL; - If usePOS is enabled and lowMem is disabled, set the size of the feature arrays (f) to the maximum number of non-nouns in an English dictionary.
MANUAL; - Create the concept neuron in the feature array of the observed column.
/MANUAL; - Do not update f and expand the observed column and global feature arrays after every new feature is detected by an observed column (e.g. process_concept_words:process_feature:expand_feature_arrays). Instead, update f and expand the observed column and global feature arrays prior to processing the concept words (e.g. process_concept_words). Create a dedicated function to detect all possible new features in the sequence, and update f and expand the observed column and global feature arrays accordingly. Update the arrays just once for a given sequence, instead of updating them incrementally for every new feature detected in the sequence. All possible new features in the sequence can be detected simply by searching for all new words (or non-nouns when in usePOS mode) in the sequence.
/MANUAL; - Only draw column feature neurons and connections if their strength is > 0, and their permanence is > 0.
MANUAL; - Maintain a concept features dictionary (of every feature name in the columns). The concept features dictionary is also saved to disk after every sentence. When useInference is enabled, the concept features dictionary is loaded from disk during startup, before processing the first sequence in the dataset.
MANUAL; - Increment the strength of the feature concept neurons
MANUAL; - Only connect column features to future or present (not past) column features. Create connections for concept neurons. 
MANUAL; - Decrease permanence of inactive connections between observed columns (not all columns). Do not remove feature neurons from columns (just set their permanence to 0). Decrease permanence of inactive connections in the same column. Add method; decrease permanence of inactive connections for activated features in column (instead of connections from inactive feature neurons in column). Move all the decrease permanence code to a separate function.
CHATONLY; - Replace all connections modification code in the functions decrease_permanence and process_feature with parallelised implementations (by multiplying/adding/subtracting their pytorch arrays instead of serially modifying their connections). All of the feature and connection arrays in the observed columns have the same number of dimensions.
CHATONLY; - Introduce sequence observed columns object arrays to improve the efficiency of training. Create a sequence observed columns class (SequenceObservedColumns) that contains sequence observed columns object arrays which stack a feature subset of the observed columns object arrays for the current sequence. Sequence observed columns object arrays are created for each feature neuron and feature connection array type currently stored within the observed columns class objects for the current sequence. The sequence observed columns object arrays only contain the features identified for the sequence (not every column feature, as is the case with the observed columns object arrays). The feature neuron arrays in the sequence observed columns class are of 2D shape cs * fs, where cs is the number of concept columns in the sequence, and fs is the number of unique features in the sequence. The feature connection arrays in the sequence observed columns class are of 4D shape cs * fs * cs * fs. The first dimension of the sequence observed columns arrays corresponds to observed column index in the sequence being processed. All other dimensions are similar to those in the original observed column object arrays (except that they contain sequence subsets cs and fs (instead of using c and f). Create a dictionary in the sequence observed columns object which maps the concept name corresponding to each observed column stored in a sequence observed columns array (key) to its index in the array (value). Populate the observed columns objects with their array data when loading the observed columns (creation of new concept column or reading from disk), as currently implemented. Once every observed column for a sequence has been loaded the sequence observed column arrays are then populated. Converted all sentence processing code to use the sequence observed columns object arrays (instead of observed columns object arrays), and the code should these arrays by passing the sequence observed columns object between functions. When the sentence has finished processing the sequence observed columns object arrays are then used to repopulate the observed columns object arrays. The observed columns object arrays are then saved (writing to disk), as currently implemented.
CHATONLY; - Parallelise all SequenceObservedColumns class operations (populate_arrays/update_observed_columns). Parallelise these serial operations by using appropriate mask arrays. Instead of using for loops, use array operations.
CHATONLY; - Parallelise the execution of process_feature. Instead of using the for loop, use pytorch array operations.
MANUAL; - Parallelise the execution of process_concept_words. Instead of using the for loop, use pytorch array operations.
MANUAL; - Use spacy instead of nltk to parse sentences. Add useDedicatedConceptNames - same word can have different pos making it classed as an instance feature or prime concept feature. Upgrade process_features to prioritise prime concept feature detection over instance feature detection.
MANUAL; - Patch process_features:feature_connections_active - only add connections for sequence activated neurons.
MANUAL; - Add dimensions to neurons and connections arrays; properties (strength, permanence, activation, time etc), type (all; with provision for action, condition, quality, modifier, concept etc). Collapse strength, permanence, activation arrays into single array (properties dim).
MANUAL; - Add sequenceObservedColumnsUseSequenceFeaturesOnly - sequence observed columns arrays only store sequence features. Add drawSequenceObservedColumns - draw sequence observed columns (instead of complete observed columns).
MANUAL; - Add useDedicatedConceptNames2 - Rename each concept neuron in observed columns/sequence observed columns to a replacement name variableConceptNeuronFeature, so that each observed column feature array has exactly the same set of features. Add SequenceObservedColumn.observed_columns_dict and SequenceObservedColumn.observed_columns_sequence_word_index_dict. Add ObservedColumn.concept_name and ObservedColumn.concept_sequence_word_index.
MANUAL; - Ensure word order is maintained for internal and external feature connections. Ensure word order is maintained for connections between columns (does not support multiple same concepts in same sentence). Ensure identical feature nodes are not connected together. Change networkx graph to directed graph. Add randomiseColumnFeatureXposition - shuffle x position of column internal features such that their connections can be better visualised.
MANUAL; - Set neuron/connection permanence increase function zf to be linear (+z1).
MANUAL; - Even when not in inference mode, load concept_columns_dict_file/concept_features_dict from database. Prepare non low memory for inference. Generalise graph draw code for all modes.
MANUAL; - Start inference mode. Update neuron activation to be cumulative (but reset upon dataset/database load). Update neuron connection activation to immediately add activation to their target nodes. Add SequenceObservedColumns.concept_indices_in_observed_list. Extract SequenceObservedColumns.identifyObservedColumnFeatureWords and SequenceObservedColumns.getObservedColumnFeatureIndices from SequenceObservedColumns.getObservedColumnFeatureWords.
MANUAL; - Start topk feature selection within topk columns.
MANUAL; - Add option sequenceObservedColumnsMatchSequenceWords: update sequence observed column arrays to store columns and features in order of sentence word index. Upgrade process features; prefer closer than further target neurons when strengthening connections or activating target neurons in sentence. Upgrade process features; add target neuron activation dependence on connection strength. Upgrade process features with option deactivateNeuronsUponPrediction; suppress neuron activations once processed. During inference, for each prediction predict both next word and column (same/diff to existing column). During inference, load an inference prompt (seed sentences) from disk. Remove useDedicatedConceptNames1. Store word.lower() in words list. Extract columns_index_sequence_word_index_dict from observed_columns_sequence_word_index_dict.
MANUAL; - Patch process_column_prediction. Extract process_features_active_train/predict from process_features_active; predict all targets in global feature arrays. Patch process_features_active; feature_connections_activation_update = feature_connections_active * feature_connections[array_index_properties_strength].
MANUAL; - Upgrade inference; once a concept column has been activated and its feature neurons have fired (connection targets have been activated), prevent them from firing again until a new concept column is activated. Upgrade inference seed phase to activate global target neurons and not train (process_column_inference_seed).
MANUAL; - Upgrade inference; draw feature neuron activation. Extract SequenceObservedColumnsInferenceSeed/SequenceObservedColumnsInferencePrediction from SequenceObservedColumns. Partially revert inference; fire feature neurons (and activate their connection targets) independently. Patch first_pass; only execute addConceptToConceptColumnsDict if pos in noun_pos_tags. Patch update_observed_columns; set global global_feature_neurons. Update process_features_active(not train):deactivateNeuronsUponPrediction to deactivate based on feature_neurons_inactive_source (i.e. mask by source concept columns only).
MANUAL; - Update process_features_active - disable activation trace during train, patch calculation of feature_neurons_inactive_source.
MANUAL; - Store feature neuron and connection last reference time and pos types in their array properties dimension (strength, permanence, activation, time, pos). Upgrade visualisation during train with option drawRelationTypes; draw feature neuron and connection relation types in different colours. Prime concept feature neurons are drawn in blue. Condition (preposition) feature neurons and their connections in green. Action (verb) feature neurons and their connections in red. Property (have auxiliary/'s) feature neurons and their connections in cyan. Quality (adjective) feature neurons and their connections in turquoise. Modifier (adverb and all other auxiliary) feature neurons and their connections in light sky blue. Definition (being auxiliary) feature neurons and their external column connections in blue. Quality (being auxiliary) feature neurons and their internal column connections in turquoise. Determiner feature neurons and their connections in magenta. Conjunction feature neurons and their connections in black (logical conditions). Quantity/Symbol feature neurons and their connections in purple. All other auxiliary feature neurons and their connections in light sky blue.
MANUAL; - Update inference; enable sequenceObservedColumnsUseSequenceFeaturesOnly during seed phase. Add option conceptColumnsDelimitByConceptFeaturesStart - constrain column feature detection to be after prime concept feature detection. Add option debugConnectColumnsToNextColumnsInSequenceOnly - connect columns to next columns in sequence only. process_features:sequenceObservedColumnsMatchSequenceWords - set columns_word_order[sequence_concept_index] = sequence_concept_index (instead of sequence_concept_word_index). Update process_column_inference_prediction; move decrement activations.
MANUAL; - Patch dependency of connection strength on word order distance. Patch process_features_active_predict.
MANUAL; - Add option increaseColumnInternalConnectionsStrength - increase column internal connections strength. Patch process_features_active:deactivateNeuronsUponPrediction to only deactivate source feature neurons (not all source feature neurons in seed concept columns).
MANUAL; - Start option inferenceSeedTargetActivationsGlobalFeatureArrays - activate entire network during inference seed phase. Extract process_features_active_train/seed from process_features_active. Update SequenceObservedColumns.update_observed_columns(mode=="applySummedChangesToConceptNeuronSequenceInstances") - ensure arrays remain positive (summation of multiple negative differences cannot result in the final array being below zero).
MANUAL; - Make sequenceObservedColumnsUseSequenceFeaturesOnly independent of sequenceObservedColumnsMatchSequenceWords.
MANUAL; - Add databaseFolder. Set torch default device to GPU. 
MANUAL; - Initialise all feature neuron and feature connection tensors to zero (only set z1 permanence when first assigning a neuron/connection).
/MANUAL; - [reverted] Convert the global feature_neurons arrays and the ObservedColumns class feature_neurons and feature_connections arrays from dense to sparse tensors.
MANUAL; - patch populate_arrays self.feature_connections generation from sparse tensors.
MANUAL; - Convert feature neuron/connections tensor redundant type dimension into SANI (sequentially activated neuronal input) segment dimension.

---
v1c (o1-preview):
MANUAL; - Create a hybrid GNN AI that comprises a database network (the abstract biological neural neural network defined previously) and a predictive network. The database network is easily modified upon encountering new information, enabling continuous learning (low energy/compute). The database network is trained using a target sequence (ground truth) and non-backpropagation algorithm. The predictive network is trained to generate next token predictions based on the database network along with the target sequence (ground truth). The AI is then capable of generating next token predictions based on a seed sequence (prompt) and its current revision of the database network. It learns to reason across/from the database network to generate its predictions. The database network is made amenable to existing LLM architectures (transformer/MLP) by structuring/storing its contents in permutation invariant assemblies.
/MANUAL; - restore option not useSANI (set array_number_of_segments = 1). add option inferencePredictiveNetwork. Create class NextWordPredictionMLPmodel. Extract predictMostActiveFeature/selectMostActiveFeature from process_column_inference_prediction.
MANUAL; - extract GIAANNproto_databaseNetworkDraw.py GIAANNproto_databaseNetworkFiles.py GIAANNproto_databaseNetwork.py GIAANNproto_databaseNetworkTrain.py GIAANNproto_globalDefs.py GIAANNproto_predictiveNetworkMLP.py GIAANNproto_predictiveNetwork.py GIAANNproto_predictiveNetworkTransformer.py GIAANNproto_main.py GIAANNproto_sparseTensors.py 
MANUAL; - patch process_features:!(sequenceObservedColumnsUseSequenceFeaturesOnly and sequenceObservedColumnsMatchSequenceWords):!useSANI: set feature_neurons_active[0, sequence_concept_index, sequence_feature_index] = 1
- Create a predictive network using a custom pytorch transformer model;
- Each column in the database network corresponds to an input token embedding in the predictive network (transformer). The database network columns are of the same dimension as the predictive network input token embeddings since they each contain a set of possible predefined features (of size f).
- The different states of the column features (properties: strength, permanence, activation, time, pos, etc) are read into different attention heads.
- The predictive network also reads the column feature connections from the database network (not just the column feature neurons). The predictive network transformer attention query key pair calculations for each attention head in the input (i.e. first) transformer layer are modified based on the database network connection state between them (properties: strength, permanence, activation, time, pos, etc).
- To derive the predicted token given the current transformer state, apply an MLP over the entire set of columns in the last layer of the transformer.
- The database network comprises a sparse global feature neuron 4D array of shape p * s * c * f, where p is the number of properties, s is the number of segments, c is the number of columns, f is the number of features. The columns in the database network have a sparse feature connection 6D array of shape p * s * c * f * c * f.
- The predictive network is a custom transformer that always predicts a single word (column index and feature index) based on the state of every input token in a permutation invariant sequence of length c. The predicted word is the index of max value within a probability distribution of 2D size c * f. The transformer has no positional encodings (complete permutation invariance). Every input token is defined as a s * p * f 3D array, where p is the number of properties per feature, s is the number of input segments, and f is the number of input features. The input layer X of the transformer is thus defined as a p * s * c * f 4D array. The s and p dimensions of the input layer are used to generate s*p attention heads in the input layer. The keys (K) and queries (Q) of the input layer are of the same shape as the input layer X (p * s * c * f), but are not used by the transformer. Instead the K*Q output of the input layer is read directly from the database network feature connections (p * s * c * f * c * f). The values (V) of the input layer are generated using the standard implementation (V = W_v * X, where W_v is of shape p * s * f * f). Each hidden (i.e. non-input) layer of the transformer uses a standard transformer implementation, with a standard hidden dimension size (f_hidden) and number of attention heads (p_hidden).
MANUAL; - The number of tokens in predictive network transformer matches the number of columns in the database network. When a token is predicted the activation levels of the database network are modified. An activation trace is stored across sentences, to enable long range reference resolution. The transformer learns to ignore currently activated neurons as likely next word predictions, as they have recently been predicted. 
MANUAL; - The precise distribution of features differentiates input token embeddings.
MANUAL; - The transformer layers can still be trained without a final version of the database network.
FUTURE; - The predictive network transformer supports cross-processing between attention heads.
MANUAL; - Remove databaseNetworkObject.global_feature_neurons_activation.
MANUAL; - Update nextWordPredictionTransformerTrainStep: do not convert to database_feature_connections.to_dense(). Replace all slice_sparse_tensor(sparse_tensor, slice_dim=0, slice_index) operations with standard pytorch indexing; sparse_tensor[slice_index].
MANUAL; - Extract option transformerUseInputConnections. Set self.f_mlp = self.embedding_dim*4.
MANUAL; - Update inferencePredictiveNetwork: enable useActivationDecrement and disable deactivateNeuronsUponPrediction.
MANUAL; - Update inferencePredictiveNetworkModelTransformer:transformerUseInputConnections - add a residual connection over the input layer. 
MANUAL; - Update process_column_inference_prediction/process_features_active_predict_*:transformerUseInputConnections - create and update global_feature_connections_activation. Patch process_column_inference_prediction; set global_feature_neurons_activation, global_feature_connections_activation = process_features_active_predict_*().
MANUAL; - add option useActivationDecrement:useActivationDecrementNonlinear.
MANUAL; - start option useInference:incrementallySeedNetwork - update inference seed phase to incrementally activate neurons (instead of batch seed neurons).
MANUAL; - update process_features_active_seed:inferenceSeedTargetActivationsGlobalFeatureArrays and seed_network to support useActivationDecrement.
MANUAL; - extract seed_network from process_concept_words_inference.
MANUAL; - patch process_concept_words_inference:incrementallySeedNetwork - execute seed_network(num_seed_tokens=1).
MANUAL; - extract createFeatureConnectionsActiveSeed from process_features_active_seed and restrict by columns_word_order.
MANUAL; - patch process_features_active_seed:createFeatureConnectionsActiveSeed:columns_word_order_mask to use first_seed_concept_index and num_seed_concepts:firstConceptIndexPredictPhase.
MANUAL; - update process_concept_words: remove redundant var numberConceptsInSeed.
MANUAL; - patch createFeatureConnectionsActiveSeed; adding of dim array_number_of_segments.
MANUAL; - start incrementallySeedNetwork:inferenceSeedTargetActivationsGlobalFeatureArrays.
MANUAL; - extract identify_seed_indices from process_features. 
MANUAL; - patch process_features_active_seed:deactivateNeuronsUponPrediction:inferenceSeedTargetActivationsGlobalFeatureArrays:indices_to_update and process_column_inference_prediction:deactivateNeuronsUponPrediction:!useSANI:indices_to_update.
MANUAL; - add option drawAllColumns for network visualisation generation across sentences. Add options drawNetworkDuringTrainSave/drawNetworkDuringPredictSave.
MANUAL; - Print article and sentence indices in command line.
MANUAL; - [reverted] Convert global and ObservedColumns feature neuron/connections tensors into lists of sparse tensors; convert properties dimension to python list.
MANUAL; - Extract options useGPUsparse/useGPUdense from useGPU for sparse/dense tensors respectively.
MANUAL; - Add maxSentenceLength.
MANUAL; - Revert changes @v1c7a.
MANUAL; - Update populate_arrays:!useGPUsparse - execute dense tensor creation operations on CPU.
MANUAL; - Update populate_arrays:!useGPUsparse - execute dense tensor creation operations on GPU, store sparse tensor indices/values lists on CPU.
- Update populate_arrays - apply optimisation to avoid creating large intermediate tensors.
MANUAL; - disable useInference:conceptColumnsDelimitByConceptFeaturesStart
MANUAL; - set !useInference:lowMem=False - independent useInference execution currently requires training with global feature neuron arrays
MANUAL; - patch GIAANNproto_databaseNetwork:loadFeatureNeuronsGlobal - if GIAANNproto_databaseNetworkFiles.pathExists(global_feature_neurons_file+pytorch_tensor_file_extension): 
MANUAL; - add option normaliseColumnSelectionByFeatureConnections. Extract option normaliseConnectionStrengthWrtContextLength.
MANUAL; - add option normaliseFeatureSelectionByFeatureConnections.
MANUAL; - add option trainPredictionNetworkAllSentences - support predictive network training on every sentence in corpus. Extract getTokenConceptFeatureIndex from predictMostActiveFeature. Update process_features_active_predict_multi. 
MANUAL; - Update trainPredictionNetworkAllSentences to explicitly activate all source tokens (incremental seed during train). Extract getTokenConceptFeatureIndexTensor from predictMostActiveFeature. Rename global kc to kcNetwork.
MANUAL; - patch process_column_inference_prediction:trainPredictionNetworkAllSentences - if(wordPredictionIndex == 1) will reactivate first seed token column feature (as it was not saved during wordPredictionIndex==0). Update process_features_active_train to initialise array_index_properties_activation to zero.
MANUAL; - patch process_concept_words_inference:!trainPredictionNetworkAllSentences - restore execution of initialisePredictiveNetwork after completing training steps in prompt. Extract option useNextTokenPredictionsOrTargetsToActivateNextColumnFeatures - next token predictions are used to activate the next column features (rather than prediction targets).
MANUAL; - add inferenceActivationFunction - required to prevent exponential runaway of activations (that negatively affect predictionNetwork loss optimisation).
MANUAL; - rename normaliseColumnSelectionByFeatureConnections*/normaliseFeatureSelectionByFeatureConnections*/useActivationDecrementNonlinear/useNeuronFeaturePropertiesTimeDuringInference/savePredictiveNetwork/useNextTokenPredictionsOrTargetsToActivateNextColumnFeatures/trainPredictionNetworkAllSentences/incrementallySeedNetwork/deactivateNeuronsUponPrediction/useActivationDecrement to inferenceNormaliseColumnSelectionByFeatureConnections*/inferenceNormaliseFeatureSelectionByFeatureConnections*/inferenceDecrementActivationsNonlinear/inferenceUseNeuronFeaturePropertiesTime/inferenceSavePredictiveNetwork/inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures/inferenceTrainPredictionNetworkAllSentences/inferenceIncrementallySeedNetwork/inferenceDeactivateNeuronsUponPrediction/inferenceDecrementActivations.
MANUAL; - rename increaseColumnInternalConnectionsStrength*/normaliseConnectionStrengthWrtContextLength/decreasePermanenceOfInactiveFeatureNeuronsAndConnections/sequenceObservedColumnsUseSequenceFeaturesOnly/trainSequenceObservedColumnsMatchSequenceWords to trainConnectionStrengthIncreaseColumnInternal*/trainConnectionStrengthNormaliseWrtContextLength/trainDecreasePermanenceOfInactiveFeatureNeuronsAndConnections/sequenceObservedColumnsUseSequenceFeaturesOnly/trainSequenceObservedColumnsMatchSequenceWords
MANUAL; - add option inferenceInvertNeuronActivationUponPrediction - set activations of previously activated neurons to negative - refractory period preventing consecutive feature reactivation and facilitating prediction based on past predictions. Update process_column_inference_prediction:inferenceDeactivateNeuronsUponPrediction.
MANUAL; - add option useGPUpredictiveNetworkModel - use GPU to train transformer/MLP predictive network model.
MANUAL; - update inferencePredictiveNetworkModelTransformer - independently predict c/f (rather than producing a single c*f matrix, produce an independent c and f matrix).
MANUAL; - update process_column_inference_prediction to always print predictions if printPredictionsDuringInferencePredict. Update getTopkPredictionsC to predict topk kcPred columns.
MANUAL; - Add option inferenceUseNeuronFeaturePropertiesTime - assign last activation time during inference. Disable inferenceInvertNeuronActivationUponPrediction.
MANUAL; - update inferenceTrainPredictionNetworkAllSentences implementation - do not train database network (expect pretrain).
MANUAL; - update process_features_active_train - if inferenceUseNeuronFeaturePropertiesTime: initialise array_index_properties_time to 0.
MANUAL; - add option !inferenceTrainPredictionNetworkBurstAllTargetsInSequence; disable bursting of all targets during training of predictive network (only burst the initial seed in the sequence).
MANUAL; - generalise option inferenceTrainPredictionNetworkBurstAllTargetsInSequence to inferenceBurstAllPredictionsOrTargetsInSequence.
MANUAL; - extract option inferenceSeedNetwork. patch process_column_inference_prediction - if(sequenceWordIndex==0 or inferenceBurstAllPredictionsOrTargetsInSequence):.
MANUAL; - add option inferencePredictiveNetworkInitialiseWeightsNearZero - help predictive model to learn faster (rely exclusively on input activation levels at start of training).
MANUAL; - add option inferencePredictiveNetworkIndependentFCpredictions. patch GIAANNproto_predictiveNetworkTransformer/MLP - do not apply softmax before nn.CrossEntropyLoss()/nn.MSELoss(). extract GIAANNproto_predictiveNetworkOperations. rename inferenceTrainPredictionNetworkAllSentences/inferenceTrainPredictionNetworkNumberEpochs to inferenceTrainPredictiveNetworkAllSentences/numberEpochs.
MANUAL; - add option transformerOutputLayerUseEveryColumn.
MANUAL; - add option inferencePredictiveNetworkUseInputAllProperties. patch inferencePredictiveNetworkModelTransformer:process_column_inference_prediction - apply initial seed burst to global arrays (before creation of global activation arrays).
MANUAL; - normalise variable naming scheme (o1/manual) - replace all snake_case names with lower camel case names.
MANUAL; - disable inferencePredictiveNetworkUseInputAllProperties.
MANUAL; - add inferencePredictiveNetworkNormaliseInputs.
MANUAL; - update inferenceUseNeuronFeaturePropertiesTime to set a max time inferenceUseNeuronFeaturePropertiesTimeActivate upon feature activation, and decrement by inferenceUseNeuronFeaturePropertiesTimeDecrement every sentence.
MANUAL; - start GIAANNproto_predictiveNetworkModelColumnMLP to first filter topk columns by summed feature activation level, then apply the same MLP prediction algorithm to every column independently, before selecting final columns/features.
MANUAL; - rename predictive network model fc to linear. rename GIAANNproto_predictiveNetworkMLP/Transformer to GIAANNproto_predictiveNetworkModelMLP/Transformer.
MANUAL; - patch nextWordPredictionMLPtrainStep - explicitly reshape tensors before feeding to model. update nextWordPredictionMLPtrainStep - execute normaliseDenseTensor(globalFeatureNeurons, dim=0), before adding batch dim.
MANUAL; - patch useInference:!inferenceTrainPredictiveNetworkAllSentences - set numPredictionTokens dynamically. if numSeedTokens >= len(sentence), ignore sentence.
/MANUAL; - replace GIAANNproto_predictiveNetworkModelColumnMLP argmax with softmax.
MANUAL; - add option inferencePredictiveNetworkModelFilterColumnsKmax - update selectMostActiveColumns to filter columns by max column activation (sparse_rowwise_max) rather than sum column activation. 
MANUAL; - add option inferenceRetainActivationsAcrossMultipleSentences - retain activations across sentences such that these can be used during training/inference.
MANUAL; - patch processFeatures:activeSequentialSegments to ensure positive; set minSequentialSegmentIndex = max(0, arrayNumberOfSegments-sequenceConceptIndex-1). patch processFeatures:featureNeuronsSegmentMask to include all segments receiving forward connections; set numberOfSegments = min(arrayNumberOfSegments, i+1).
MANUAL; - add ignoreNewlineCharacters - ignore new line characters (do not parse).
MANUAL; - update processFeaturesActivePredictSingle for useSANI (sum activations across all segments). update processFeaturesActivePredictSingle/Multi to select conceptIndex column from sequenceObservedColumnsPrediction.featureConnections. extract processFeaturesActivePredict from processFeaturesActivePredictSingle.
MANUAL; - add option algorithmMatrixSANImethod="enforceActivationAcrossSegments" - only activate a segment if previous segment active.
MANUAL; - normalise across SANI segments independently - set inferencePredictiveNetworkNormaliseDim=1. depreciate sparse tensor normalise option (only normalise once converted to dense tensors).
MANUAL; - update processColumnInferencePrediction - replace modifySparseTensor with addElementValueToSparseTensor to support case where sparse tensor element is empty.
MANUAL; - add option connectionsStrengthBoolean - use boolean synaptic connectivity. add option activationStrengthBoolean - use boolean segment activation strength (once a segment is activated, do not increase its activation level).
MANUAL; - update getTokenConceptFeatureIndexTensor:getTokenConceptFeatureIndex to not predict 2 columns for prime concept features.
MANUAL; - update GIAANNproto_databaseNetworkDraw to print all SANI segment values.
MANUAL; - add option multisentencePredictions - support multisentence predictions. Rename all instances of sentence/doc to sequence.
MANUAL; - update GIAANNproto_main:processSequence to remove backupGlobalArrays/restoreGlobalArrays if(inferencePredictiveNetwork) condition.
MANUAL; - start SANIconceptNeurons - execute preprocessor to allocate neurons to non-noun tuples for each concept.
MANUAL; - add SANIconceptNeuronsAllocateForPartialSubsequences - assign SANI concept neurons for partial subsequences (2, 3, 4, etc word tuples; not just x word tuples where x is the length of the non-noun word tuple).

---
v1d (Codex IDE GPT-5.1-Codex):
- add proto GIAANNproto1d1a - start inferenceBeamSearch
	Please implement a beam search prediction algorithm according to this specification:
	If inferenceBeamSearch = True:
		- Activate every token in sequence prompt (and resolve their connection target neuron updates).
		- For every prediction in sequence:
			- Perform beam search along inferenceBeamWidth and inferenceBeamDepth
				- Maintain independent network activations for every beam search path (they should not conflict).
				- For each prediction in beam search path, resolve their connection target neuron updates.
				- If inferenceBeamSearchConceptColumns = True perform beam search along concept columns (ie select topk next most activated concept columns).
				- ElseIf inferenceBeamSearchConceptColumns = False perform beam search along instance nodes within columns (ie select topk next most activated nodes in any network column).
				- Record the total activation of all executed nodes in path (respect inferenceBeamScoreStrategy). 
			- Calculate the execution path that results in the highest total activation values.
			- Take the next most activated concept column (inferenceBeamSearchConceptColumns=True) or instance node (inferenceBeamSearchConceptColumns=False) as the next prediction.
			- If inferenceBeamSearchConceptColumns=True only: then execute every most activated node within the predicted concept column (above a certain activation threshold). 
	Elseif inferenceBeamSearch = False:
		- Retain original prediction method(s) - apply no changes to the original codebase
	I have added dev/GIAANNproto_predictiveNetwork-processColumnInferencePrediction-beamSearchExample.py with example beam search code (do not use this but it may help you with your implementation of the required specification).
- update inferenceBeamSearch - deactivate nodes along beam search path during search
- update printPredictionsDuringInferencePredict for inferenceBeamSearch
- patch beam search scoring so candidates are evaluated after their activations propagate, allowing deeper paths to influence the result.
- update candidate generation to operate directly on sparse activation/strength data, avoiding full dense conversions during the search.
- inferenceBeamSearchConceptColumns: normalise concept-column candidates by averaging their node activations/connections so wide columns no longer dominate purely by node count.
- refine beam-search scoring so each expansion runs in a cloned state, measures the positive activation delta after firing candidate nodes, and updates cumulative scores accordingly
- Added concept-column candidate activation totals to beam scoring when inferenceBeamScoreStrategy is nodeActivation, ensuring column predictions reflect summed node activity rather than per-step deltas.
- Selected the best beam from both active and completed paths so the emitted depth-0 action always comes from the highest-scoring trajectory.
- Updated the beam search review document to reflect the revised scoring and path-selection behavior while noting current and future configuration options.
- Added optional configuration flags to enable column-aware beam-search heuristics while keeping defaults unchanged when disabled.
- Implemented column-scoring logic for instance-node beam search, incorporating active-node counts, internal connectivity, and adjacent-column overlap before selecting candidate nodes.
- if useInference and inferenceTrainPredictiveNetworkAllSequences: add ensurePredictiveInferenceDatabaseReady to check for existing trained databaseNetwork before running prediction
- add option trainConnectionStrengthPOSdependence=True - different nodes receive different external column (ie intercolumn) connection strength modification based on their source POS. The modification of their connection strengths will be higher/lower depending on the source node POS; connectionStrengthPOSdependenceTypes, connectionStrengthPOSdependenceValues.
- add option inferenceConnectionStrengthPOSdependence=True - in which the connection strength modifiers do not affect stored connection strengths during training, but instead affect the immediate next token predictions during inference. The connection modifiers are applied during inference to bias the next token prediction, but these modifiers are immediately disgarded do not affect subsequence token prediction. Recommended implementation: the connection modifiers are applied to existing trained connection weights to temporiarily bias the immediate (subthreshold) activation strengths of the nodes in the network, but these temporary biases are immediately disgarded after the next token prediction (selection) has occured.
- add option connectionStrengthPOSdependenceExternal=False - in which the connection strength modifiers are applied to both internal and external connections (during train if trainConnectionStrengthPOSdependence, or inference if inferenceConnectionStrengthPOSdependence).
- implement option conceptColumnsDelimitByPOS=True - delimit concept columns by specific pos types (conceptColumnsDelimiterPOStypes) instead of prime concept features (conceptColumnsDelimitByConceptFeaturesStart/Mid).
- also update the prediction algorithm to support conceptColumnsDelimitByPOS=True (for both case inferencePredictiveNetwork=True/False and case inferenceBeamSearch=True/False) to always predict an external concept column node if the current activated node is of type isReferenceSetDelimiter (conceptColumnsDelimiterPOStypes), else always predict an internal concept column node.
- conceptColumnsDelimitByPOS=True needs to be able to detect whether a node in a concept column (e.g. currently activated node) is of type isReferenceSetDelimiter. To achieve this I recommend that you do not update the GIA database network to store a flag, but instead create and execute the python function isWordReferenceSetDelimiterType(nodeNameString) on demand. If you think you can instead update the GIA database network to store this flag, then inform me how you wish to do this before starting your implementation.
- implement option predictionColumnsMustActivateConceptFeature=True - columns must activate their prime concept feature node during prediction. I.e. never predict an external column node unless (until) its prime concept feature node has already been predicted. Ensure that this requirement is respected by inferenceBeamSearch also.
- implement option pretrainCombineConsecutiveNouns - during sentence preprocessing combine consecutive nouns/propernouns (NOUN/PROPN) into a single word, delimited by '_'.
- update conceptColumnsDelimitByPOS train method - when detecting concept column delimiters during train (conceptColumnsDelimiterPOStypes), and if there is more than one consecutive concept column delimiter in the sequence, then take the last word in the subsequence as the consecutive concept column delimiter. 
- update conceptColumnsDelimitByPOS prediction method - if a currently activated node is of type reference set delimiter (conceptColumnsDelimiterPOStypes), then must predict either an external node or an internal node that is also a reference set delimiter. 
- add option predictionEnsureConnectedToPreviousPrediction - ensure that every new prediction is connected to its previously predicted node (for both internal and external connections).
MANUAL; - upgrade spacyModelName = 'en_core_web_trf' (orig: 'en_core_web_sm').
- add pretrainCombineConsecutiveNouns() and pretrainRenamePunc() to pretrain(). 
- implement option detectReferenceSetDelimitersPunctComma=True; in pretrainRenamePunc(); If "," is proceeded by a NOUN without a intermediate POS based reference set delimiter (conceptColumnsDelimiterPOStypes), then rename "," to ",,". ",," will then be detected as a reference set delimiter below.
- if conceptColumnsDelimitByPOS=True: update processConceptWords() to detect conceptColumnsDelimiterPUNCtypes (semicolons ";", colons ":", full stops ".", and ",,") as reference set delimiters. 
- add databaseNetworkObject.conceptFeaturesReferenceSetDelimiterList.
- add option arrayIndexPropertiesMinWordDistance=True. 1. in train; if arrayIndexPropertiesMinWordDistance=True, record the minimum word distance of every trained connection (overwriting this accordingly with any lower value than its currently stored value). 2. in inference ;if arrayIndexPropertiesMinWordDistance=True, ensure that the connection minWordDistance between every predicted node in the inference phase = 1 exactly (including in inferenceBeamSearch).
- add option debugConnectNodesToNextNodesInSequenceOnly.
- patch predictionEnsureConnectedToPreviousPrediction - ensure no fallback strategy
- patch predictionColumnsMustActivateConceptFeature
- patch debugConnectColumnsToNextColumnsInSequenceOnly
- add class SequenceToken, and pass tokens between functions instead of words, lemmas, posTags.
- implement option detectReferenceSetDelimitersBetweenNouns in isFeaturePOSreferenceSetDelimiterType (using detectReferenceSetDelimitersBetweenNounsPOStypes and detectReferenceSetDelimitersBetweenNounsWordTypes) - assign probabilistic reference set delimiters if they are detected inbetween nouns without deterministic delimiters (previously detected via conceptColumnsDelimiterPOStypes, conceptColumnsDelimiterWordTypes). If there is more than one probabilistic reference set delimiter detected, then take the first one detected (add a comment to allow this condition to be upgraded in the future).
- upgrade the prediction phase to support detectReferenceSetDelimitersBetweenNouns=True probabilistic reference set delimiters. a) maintain the same requirements for case isFeatureIndexReferenceSetDelimiterDeterministic()==True: if previously predicted node is a reference set delimiter then must either predict an external node or an internal node that is also a reference set delimiter (no change to functionality). b) add an additional requirement for case isFeatureIndexReferenceSetDelimiterProbabilistic(): if previously predicted node isFeatureIndexReferenceSetDelimiterProbabilistic()==True then support prediction of either an internal or an external node.
MANUAL; - patch processFeatureDetection:conceptColumnsDelimitByPOS - compute isDelimiterProbabilistic for case featureWord in databaseNetworkObject.conceptFeaturesDict. 
- patch predictionEnsureConnectedToPreviousPrediction
MANUAL; - extract isConcept() and add nounTags checks
MANUAL; - extract GIAANNproto_tokens
MANUAL; - add conceptColumnsDelimiterTagTypes/detectReferenceSetDelimitersBetweenNounsTagTypes
MANUAL; - patch conceptColumnsDelimitByPOS - use sequenceReferenceSetDelimiterList
- patch GIAANNproto_databaseNetwork.py:getTokenConceptFeatureIndexTensor(): if(conceptMask[sequenceWordIndex]): targetFeatureIndex = featureIndexConceptNeuron
MANUAL; - update GIAANNproto1d.nlc with full change history (including both specification and patches)
MANUAL; - rename files from *predictiveNetwork* -> *prediction*, extract GIAANNproto_predictionNetwork, GIAANNproto_predictionSeed, GIAANNproto_predictionActivate, GIAANNproto_sequenceConcepts, GIAANNproto_sequenceObservedColumns, rename GIAANNproto_sequenceTokens
- patch populateArrays() (seed activations) - execute self.mapGlobalToLocalIndices() and self.computeColumnLocalFeatureMaps(tokens)
- allow beam predictions to retain real features by removing prime concept feature neuron overrides and updating concept activation tracking.
- add minimumPredictionActivationThreshold - explicit threshold application (for verification only).
- Please verify the conceptColumnsDelimitByPOS requirement specification: Each prediction step in both standard inference and beam search predicts the currently most activated directly connected feature (assuming its activation is above 0.0) under these constraints: 1. if currently predicted node is in conceptFeaturesReferenceSetDelimiterProbabilisticList: it must predict either a) a directly connected node in an external column or b) a directly connected node in its own (internal) column. 2. elif currently predicted node is in conceptFeaturesReferenceSetDelimiterDeterministicList: it must either predict a) an external concept column node it is directly connected to or b) another reference set delimiter node (in either conceptFeaturesReferenceSetDelimiterDeterministicList or conceptFeaturesReferenceSetDelimiterProbabilisticList) it is directly connected to in its own (internal) column. 3. else (ie not reference set delimiter): the currently predicted node must predict a directly connected node in its own (internal).
- patch deterministic reference set delimiters constraint - let delimiter-mode column filtering treat both deterministic and probabilistic reference-set delimiters as valid internal targets.
- add option detectIsolatedReferenceSetDelimiters - assign isolated reference set delimiters to the next concept column. Please resolve issue of isolated ADP reference set delimiters by implementing option detectIsolatedReferenceSetDelimiters=True, where detectIsolatedReferenceSetDelimitersPOStypes = [ 'ADP']. Add this detectIsolatedReferenceSetDelimiters algorithm in processConceptWords(); 1. if a reference set delimiter is in detectIsolatedReferenceSetDelimitersPOStypes and is either a) the first token in a sequence, or b) immediately follows a previous reference set delimiter (e.g. conceptColumnsDelimiterWordTypes "."), then label it an isolated reference set delimiter (isIsolatedReferenceSetDelimiter=True). 2. assign isolated  reference set delimiters to their next column (to the right).
- Add feature position SANI segment option - patch GIAANN to implement useSANIcolumns=False option
- patch enforceDirectConnectionsSANI:useSANIcolumns=False - assignFeatureConnectionsToTargetSegments
MANUAL; - add option drawSegmentsTrain - draws connection colours based on their target node incoming segment index
MANUAL; - update applyConnectionStrengthPOSdependenceInference/computeConnectionMinWordDistanceMask - remove soft failure modes
MANUAL; - rename agent_instructions.md to AGENTS.md standard
- update useSANIcolumns:enforceActivationAcrossSegments:enforceLastSegmentMustBeActive to ignore final (ie internal) segment, as some feature neurons do not have internal column inputs
MANUAL; - add option enforceSequentialActivationAcrossSegments:enforceSequentialActivation=False
MANUAL; - rename doNotEnforceSequentialityAcrossSegments/enforceSequentialActivationAcrossSegments->doNotEnforceActivationAcrossSegments/enforceActivationAcrossSegments
- split bool useSANIcolumns=True/False into 3 options; useSANIcolumns, useSANIfeatures, useSANIfeaturesAndColumns - where useSANIfeaturesAndColumns applies arrayNumberOfSegmentsColumnDistance segments to the nearest arrayNumberOfSegmentsColumnDistance columns (internal column excluded), and arrayNumberOfSegmentsFeatureDistance segments to the nearest arrayNumberOfSegmentsFeatureDistance features. useSANIcolumns and useSANIfeatures are already defined by useSANIcolumns=True/False respectively.
- add option trainConnectionStrengthLimitTanh - which thresholds each connection strength using a tanh function at the end of the train process.
- add option trainConnectionStrengthLimitMax - which thresholds each connection strength using a simple celing (1.0) throughout the training process.
- patch useSANIfeaturesAndColumns - assign column segments first, then feature segments. OK then, we have identified an issue with your implementation of useSANIfeaturesAndColumns. The segments must be assigned to the columns first, then the nearest features. The reason this is required is because of the way enforceSequentialActivation works; segments are only ever activated if a previous segment is activated; and earlier segments in the trace (ie column segments) get activated first. Please update the useSANIfeaturesAndColumns implementation to assign column segments first, then feature segments.
- patch case useSANIfeaturesAndColumns=True so that the first feature segment (ie at arrayNumberOfSegmentsFeatureDistance from target, stored at index arrayNumberOfSegmentsColumnDistance in the segment array) only captures connections at that specific distance, instead of at this distance or any greater distance.
- patch processFeaturesActiveTrain:createFeatureConnectionsActiveTrain - unify SANI training across segments by aggregating per-segment activations instead of only using arrayIndexSegmentLast, ensuring every distance bucket contributes to connection building and permanence updates.

---
v1e (Codex IDE GPT-5.1-Codex->GPT-5.2-Codex):
- add proto GIAANNproto1e1a - start useInhibitoryNeurons
	implement option useInhibitoryNeurons:trainInhibitoryNeurons=True in GIAANNproto_databaseNetworkTrainInhibition.py:processFeaturesInactiveTrain():
		- [A] For each new feature declared in a concept column, declare an inhibitory neuron (maintains approx same number of excitatory and inhibitory neurons).
		- [B] Declare temp sequenceObservedInhibitoryNeurons list
		- [C] For each trained feature neuron in sequence:
			1. identify all alternate prediction candidate features in network - i.e. all direct (if enforceDirectConnections=True) connection targets of previous feature neuron in trained sequence except for current feature neuron in trained sequence.
			2. select the inhibitory neuron associated with that feature node (ie same column index and feature index as the trained excitatory neuron).
			3. Add (or update the weight) a connection between the inhibitory neuron and each of the identified alternate prediction candidate features.
			4. add the identified inhibitory neuron to sequenceObservedInhibitoryNeurons
		- [D] Train all the inhibitory neuron source connections exactly the same way as the excitatory (i.e. feature) neuron source connections: upgrade and execute processFeaturesActiveTrain(). i.e. for each excitatory target feature trained in source sequence, an inhibitory target feature is also trained.
		Store all excitatory neurons and connections in separate database structures and database files to inhibitory neurons and connections. Ensure that there is absolutely zero modification of the original excitatory database structures, files, and code.
MANUAL; - patch loadFeatureNeuronsGlobal - if pathExists(globalFeatureNeuronsFileFull)
MANUAL; - add option !inferencePredictiveNetwork:inferenceDecrementActivations = True
MANUAL; - restore patch case useSANIfeaturesAndColumns=True so that the first feature segment only captures connections at that specific distance
- upgrade trainInhibitoryNeurons step "1. identify all alternate prediction candidate features in network" to support option enforceDirectConnections (either method enforceDirectConnectionsSANI or method enforceDirectConnectionsMinWordDistance) - i.e. all direct (if enforceDirectConnections=True) connection targets of previous feature neuron in trained sequence except for current feature neuron in trained sequence.
MANUAL; - update enforceDirectConnectionsSANI to use existing useSANI defaults
- implement the option inferenceInhibitoryNeurons=True - for every prediction step (predicted feature):
	1. the network inhibitory neurons are activated (via their input connections) using exactly the same code as the excitatory neurons (share existing code do not replicate code for this step). 
	2. the network excitatory feature neurons have their activations modulated (downregulated) by the inhibitory output signal of the inhibitory neurons (via their output connections).
	3. the next feature predictions are thus modified by this inhibition signal.
MANUAL; - extract common excitatory/inhibitory code insertSequenceObservedColumnIntoObservedColumnFeatures/insertSequenceObservedColumnIntoObservedColumnConnection
MANUAL; - extract GIAANNproto_sequenceObservedColumnsInhibition/GIAANNproto_databaseNetworkFilesInhibition/GIAANNproto_databaseNetworkInhibition/GIAANNproto_databaseNetworkTrainInhibition
MANUAL; - restore option enforceDirectConnectionsSANIminimal - use useSANIfeatures and arrayNumberOfSegments=2 and enforceSequentialActivation=False
MANUAL; - rename GIAANNproto_sequenceObservedColumnsExcitation/GIAANNproto_databaseNetworkFilesExcitation/GIAANNproto_databaseNetworkExcitation/GIAANNproto_databaseNetworkTrainExcitation/GIAANNproto_databaseNetworkDrawExcitation, extract GIAANNproto_databaseNetworkDrawInhibition
- Please upgrade option trainInhibitoryNeurons to ensure a unique inhibitory node is assigned for every excitatory node in the network. Change specification step 2 from "identify an inhibitory neuron in the column that is not connected to the trained feature" to select the inhibitory node associated for that feature node (ie same column index and feature index). When drawing the inhibitory nodes (GIAANNproto_databaseNetworkDrawInhibition), the inhibitory neurons should be named according to their corresponding excitatory feature node name. For reference, this is how you originally implemented the trainInhibitoryNeurons algorithm, as it is the most basic interpretation.
- There is an issue with the implementation of trainInhibitoryNeurons - please re-read the specification (in GIAANNproto1e.nlc). Please ensure that;
	[D]. The input connections of each inhibitory neuron in the sequence should be trained exactly the same as the excitatory neurons in the sequence (executes the same code processFeaturesActiveTrain) - ie each inhibitory neuron should have input connections added for every prior excitatory node in the sequence. 
	[C3]. The output connections of each inhibitory neuron should only be added for its identified alternate prediction candidate features [C1.]. If no alternate prediction candidate features are identified, no output connections should be added to the inhibitory node.
- update inferenceInhibitoryNeurons inhibitory neuron firing:
	- 1. the network inhibitory neurons are activated (via their input connections) using exactly the same code as the excitatory neurons (share existing code do not replicate code for this step). As the inhibitory input connections are identical to the excitatory input connections, the inhibitory neuron that should be selected to fire should be exactly the same neuron as the excitatory neuron that fires. a) verify that this is the case, and b) add a printe statement to catch when this does not occur.
	- 2. add option inferenceInhibitoryNeuronsOptimised=True - which skips the standard inhibitory neuron activation calculation (1.) and simply selects the inhibitory neuron to fire that is associated with the excitatory feature neuron that fired. This should be close to a single line of code. if inferenceInhibitoryNeuronsOptimised=False, then revert to method 1.
- update GIAANNproto_databaseNetworkTrainInhibition to support detection of alternate prediction candidates external to the trained sequence
- add options inferenceDeactivateNeuronsUponPredictionInhibitory/inferenceDecrementActivationsInhibitory
[GPT-5.2-Codex:]
- patch inference seeding to use any active segment features for seed connections
- patch inferenceDeactivateNeuronsUponPredictionInhibitory/inferenceDecrementActivationsInhibitory
- enable useSANI+inferenceConnectionsStrengthBoolean+inferenceSegmentActivationsBoolean
- sync arrayNumberOfSegments with numSeedTokensInference
- every feature that fires must deactivate when fired if inferenceDeactivateNeuronsUponPrediction = True, even during seed phase.
- every next predicted token must have minimum distance=1 from the last predicted token when enforceDirectConnectionsMinWordDistance=True - this constraint must be enforced always (even just after completing the seed phase).
- when useSANI:enforceSequentialActivation=True the connection target node segments of the a) seeded and b) predicted nodes must activate according to the algorithmMatrixSANImethod="enforceActivationAcrossSegments rules: only activate a segment if previous segments active - see processFeaturesActivePredict(). Please patch this issue; both a) and b), and add a comment describing the issue being patched.
- when useSANI:algorithmMatrixSANIenforceRequirement="enforceLastSegmentMustBeActive=True; during prediction (including the first predicted node after seed), a node can only be selected to fire if its last segment is active - see neuronActivationSparse(). If this requirement is not being enforced, then apply a patch and add a comment.
- implement option inferenceSourceActivationsBoolean - during inference each neuron that is selected to fire uses a source activation signal of 1 (irrespective of whether useSANI=True/False).
- implement option inferenceSegmentActivationsBooleanFeatureSegmentsOnly - which only converts target segment activations into a boolean 1/0 value if they are feature segments (not concept segments). It restricts inferenceActivationStrengthBoolean to a) case useSANIfeatures or b) case useSANIfeaturesAndColumns last arrayNumberOfSegmentsFeatureDistance segments.
- patch useSANIfeaturesAndColumns - segment activation is based on a) concept column index (for first arrayNumberOfSegmentsColumnDistance segments), and then b) word index (for last arrayNumberOfSegmentsFeatureDistance segments).
- patch useSANIfeaturesAndColumns:assignFeatureConnectionsToTargetSegments - feature segments are assigned for any column (not just the internal column).
- update option useSANIfeaturesAndColumns - concept segments also include internal column segment (not just external column segments).
- update option useSANIfeaturesAndColumns - make enforceSequentialActivation independent for concept segments and feature segments (i.e. will accumulate concept and feature segments independently).
- Rather than a) performing sequence training (processFeaturesActiveTrain) by extracting dense sequence tensors from the sparse feature/connection database network tensors (via populateArray), train the dense tensors, and then inserted the trained dense tensors back into sparse feature/connection database network tensors (via updateObservedColumns), b) initialise the sequence dense tensors as all zeros for training (remove populateArray), train the dense tensors, and then insert the trained dense tensors back into sparse feature/connection database network tensors (via updateObservedColumns). Update the observed columns sparse connections tensor properties (via updateObservedColumns) efficiently using these rules; arrayIndexPropertiesStrengthIndex (addition), arrayIndexPropertiesPermanenceIndex (addition), arrayIndexPropertiesActivationIndex (replace: eg clear then add), arrayIndexPropertiesTimeIndex (replace: eg clear then add), arrayIndexPropertiesPosIndex (replace; eg clear then add), arrayIndexPropertiesMinWordDistanceIndex (take minimum). It is very important that you focus on optimising the efficiency of this update function. 
- add option drawSparseArrays - can draw sequences contained within much larger databases without running out of memory (due to densifying arrays).
- Boolean option arrayIndexPropertiesMinWordDistance=True/False currently controls whether the train process (eg processFeaturesActiveTrain(), updateObservedColumns()) trains arrayIndexPropertiesMinWordDistanceIndex. All other arrayIndexProperties are currently implemented in the train process without the ability to switch them off. Please implement options arrayIndexPropertiesStrength=False, arrayIndexPropertiesPermanence=False, arrayIndexPropertiesActivation=False, arrayIndexPropertiesTime=False, arrayIndexPropertiesPos=False. The only code that should change is the addition of these boolean if statements, nothing else should change (eg processFeaturesActiveTrain(), updateObservedColumns()). When these options are disabled, it is important that there is no redudant code executed in the train process that would unnecessarily slow down the train process (eg processFeaturesActiveTrain(), updateObservedColumns()).
- verify that the featureNeurons and featureConnections arrays (including globalFeatureNeurons) are only ever created with the properties defined in GIAANNproto_globalDefs (i.e. arrayIndexPropertiesStrength, arrayIndexPropertiesPermanence, arrayIndexPropertiesActivation, arrayIndexPropertiesTime, arrayIndexPropertiesPos, arrayIndexPropertiesMinWordDistance). The only exception to this rule is during inference (useInference=True), where arrayIndexPropertiesActivationIndex is always created for featureNeurons (or globalFeatureNeurons), but still never trained when arrayIndexPropertiesActivation=False. The file save process will likewise only save the featureNeurons and featureConnections (including globalFeatureNeurons) array properties defined in GIAANNproto_globalDefs - this should happen automatically and no changes should be required to the file save code. Please go ahead and implement this upgrade. In GIAANNproto_globalDefs, make sure to dynamically set arrayIndexPropertiesStrengthIndex, arrayIndexPropertiesPermanenceIndex, arrayIndexPropertiesActivationIndex, arrayIndexPropertiesTimeIndex, arrayIndexPropertiesPosIndex, arrayIndexPropertiesMinWordDistanceIndex, based on the values of arrayIndexPropertiesStrength, arrayIndexPropertiesPermanence, arrayIndexPropertiesActivation, arrayIndexPropertiesTime, arrayIndexPropertiesPos, arrayIndexPropertiesMinWordDistance.
- patch enforceDirectConnectionsSANI:algorithmMatrixSANIenforceRequirement="enforceLastSegmentMustBeActive" to perform direct connection detection before they become prediction candidates (like enforceDirectConnectionsMinWordDistance).
MANUAL; - add option arrayIndexPropertiesEfficient:arrayIndexPropertiesStrength=True
MANUAL; - set !useInference:useGPUsparse=True
MANUAL; - move inactive code to archive (GIAANNproto_predictionNetwork*, GIAANNproto_*Inhibition)
- improve the speed of the arrayIndexPropertiesEfficient:arrayIndexPropertiesStrength addition operation (eg in updateObservedColumns) during train, that is used to insert the trained dense sequence neuron/connection strengths back into the sparse database network neuron/connection arrays. Please upgrade the train code to create a separate path for arrayIndexPropertiesEfficient=True only (while leaving the existing implentation unchanged within case arrayIndexPropertiesEfficient=False). Implement all your recommended optimisations within the arrayIndexPropertiesEfficient=True context. Currently focus on the optimisations that you think will provide the most significant performance boost. Assume the strength values being added are always non-negative.

---
v1f (Codex IDE GPT-5.2-Codex):
- add proto GIAANNproto1f1a - upgrade GIAANN to support option multipleDendriticBranches=True:
	a) add a dendriticBranch dimension to the featureNeurons and featureConnection arrays (including global arrays) before the arrayNumberOfSegments dimension. Upgrade the entire codebase to support this change.
	b) when multipleDendriticBranches=True: declare numberOfDendriticBranches=5, else: declare numberOfDendriticBranches=1 in global defs.
	c) When multipleDendriticBranches=True: detect any repeated column features instances detected in a trained sequence. train each repeated column feature instance in a separate branch (its source feature connection branch and target feature node branch). When multipleDendriticBranches=False, assign all connections to the first branch.
	d) When multipleDendriticBranches=True: during inference only deactivate the specific activated branch after a neuron fires (leave the segment activations of all other branches unchanged). When multipleDendriticBranches=False, effectively collapse/ignore the branch dimension during inference.
	When multipleDendriticBranches=False, the code should therefore execute exactly as is (no changes should observed). All multipleDendriticBranches=True specific code should be contained within an if(multipleDendriticBranches) context.
- implement option inferenceTrainFirstSequences = False - interprets all sequences in inference_prompt.txt as independent prediction seed/target sequences. Note option inferenceTrainFirstSequences=True is already implemented (trains first sequences in inference_prompt.txt, then performs inference only on last sequence).
- add option attachTrailingTokensToLastConcept - attach tokens after the final concept to that last column.
- remove summing across branches during selection - selection is performed based on the most activated branch across all neurons in the network (that satisfy the algorithmMatrixSANIenforceRequirement="enforceLastSegmentMustBeActive" requirements).
MANUAL; - update readme
MANUAL; - sort global defs
MANUAL; - print inferenceTrainFirstSequences phase
MANUAL; - move inactive code to archive (GIAANNproto_sequenceSANIconceptNeurons/GIAANNproto_predictionInhibition)
MANUAL; - patch useSANIfeaturesAndColumns parameters
- add fallback when no prime concept feature found within seed (throw warning)
- implement debugPrintTrainSequenceDelimiters, which prints the "Processing sequenceCount" statement with the delimiter types (non, deterministic, indeterministic) of each token.
- upgrade the concept assignment token segmentation algorithm as follows: a) use the right most deterministic delimiter between two concept tokens if existent, else b) use the right most indeterministic delimiter between two concept tokens existent, else c) throw a warning ("no delimiter detected between concept tokens") and skip training the sequence. 
- implement debugPrintTrainSentenceConceptAssignment - print each sequence token with the name of its associated concept column in brackets.
- update seed phase (including getTokenConceptFeatureIndex) to use the known concept columns from the complete full seed+target sequence. The issue relates to the fact during a seed it is technically not known what column a token succeeding the last prime concept feature (or its nearest delimiter) belongs to - even though this information is embedded in the inference seed+target sequence. During the development phase of GIA however will assume that the correct concept column is known during seed - to simplify the process and speed up development.
MANUAL; - add '(' to detectReferenceSetDelimitersBetweenNounsWordTypes - allow isolated bracketed nouns to occur after other nouns
- implement options drawBranchesTrain/drawBranchesInference (drawBranches in visualizeGraph).
- Each sequence (either 1 sentence or multiple sentences if multisentencePredictions enabled) must be pos tagged independently.
- add debugPrintSequenceObservedColumnsConnections - debug connections with multiple concept column references during train sequences
MANUAL; - add debugPrintTrainSequenceConceptAssignmentByLine - display each column on a new line
- patch secondPass to not overwrite observedColumnsDict[lemma]
- patch assignment of repeated features to independent dendritic branches
- add debugOnlyDrawBranchIndexConnections
- patch updateObservedColumnsVerbose() - repeated concept multi-branch training/inference merges (for inference)
- patch processArticle spacy - skip whitespace-only sequences before re-running spaCy on sentence spans
- patch createFeatureConnectionsActiveTrain - adjusted repeated-feature mapping so inference keeps branch-specific occurrences when loading observed column
- add option debugTerminateInferenceOnPredictionTargetMismatch
- patch featurePredictionTargetMatch to still match concept features when the token lemmas are the same but their words are different - concept features should be ambivalent to their morphology (eg plural noun vs singular noun)
MANUAL; - update processColumnInferencePrediction - always calculate featurePredictionTargetMatch
MANUAL; - remove debugPrintSequenceObservedColumnsConnections/debugPrintInferencePredictionIssue/debugTerminateInferenceOnPredictionTargetMismatch

---
v1g (Codex IDE GPT-5.2-Codex):
- add proto GIAANNproto1g1a - upgrade the GIAANN inferenceUseNeuronFeaturePropertiesTime=True implementation:
	a) store the last timeValue a branch (multipleDendriticBranches) segment (useSANI) was activated in its arrayIndexPropertiesTime property (during each prediction step).
		- pseudo code for feature segment time calculation (useSANIfeatures or useSANIfeaturesAndColumns and segmentIndex >= arrayNumberOfSegmentsColumnDistance): 
			- timeValue = sequenceWordIndex (current sequence word index)
		- pseudo code for column segment time calculation (useSANIcolumns or useSANIfeaturesAndColumns and segmentIndex < arrayNumberOfSegmentsColumnDistance):
			- timeValue = sequenceColumnIndex (current sequence column index = the number of consecutive columns that have been activated in the sequence)
		- if inferenceUseNeuronFeaturePropertiesTimeExact: only allow segment activation when the time difference between the current timeValue and the previous segment timeValue is exactly 1.
	b) use arrayIndexPropertiesTime to temporarily modify the activation of each branch (multipleDendriticBranches) segment (useSANI) when selecting the next feature node to activate (during both standard inference and beam search).
		- calculate timeValue (use same function above).
		- each branch segment activation is temporarily modified based on how closely the last time it was activated (arrayIndexPropertiesTime) maps to its segmentIndex.
		- pseudo code for feature segments (useSANIfeatures or useSANIfeaturesAndColumns and segmentIndex >= arrayNumberOfSegmentsColumnDistance): 
			modifiedActivation = currentActivation - abs(currentTimeValue-arrayIndexPropertiesTime - (numberFeatureSegments-featureSegmentIndex)) 
		- pseudo code for column segments (useSANIcolumns or useSANIfeaturesAndColumns and segmentIndex < arrayNumberOfSegmentsColumnDistance):
			modifiedActivation = currentActivation - abs(currentTimeValue-arrayIndexPropertiesTime - (numberColumnSegments-columnSegmentIndex))
		- ensure the code is executed vectorised across segmentIndex (do not use python for loop for each segmentIndex).
		- if useSANIfeaturesAndColumns: feature and column segments should be processed separately using the same function (the pseudo code is same in both cases; only segment indices differ).
		- if inferenceUseNeuronFeaturePropertiesTimeExact: skip inferenceUseNeuronFeaturePropertiesTime step b.
		- ensure that all time modifications are applied to activations after inferenceSegmentActivationsBoolean is already applied to segments (ie time modification is always applied).
	When implementing inferenceUseNeuronFeaturePropertiesTime, ensure to add comments referencing the precise specification step (a - b).
MANUAL; - remove old inferenceUseNeuronFeaturePropertiesTime=True (inference time record) and inferenceUseNeuronFeaturePropertiesTime=False (train time record) implementations.
- restore inferenceUseNeuronFeaturePropertiesTime to the original spec - store the last timeValue a branch (multipleDendriticBranches) segment (useSANI) was activated in its arrayIndexPropertiesTime property (during each prediction step).
- update processColumnInferencePrediction - throw runtime error when no conceptColumnsIndicesPred.
- implement option inferenceUseNeuronFeaturePropertiesTimeExact - only fire neurons if the last times recorded were ideal (ie exact times expected for each segment index).
- implement option randomlyAssignBranches - for each feature in the train sequence randomly select a branch to be trained.
- update the inferenceUseNeuronFeaturePropertiesTimeExact implementation as follows: 
	in step a) if inferenceUseNeuronFeaturePropertiesTimeExact: only allow segment activation when the time difference between the current timeValue and the previous segment timeValue is exactly 1.
	in step b) if inferenceUseNeuronFeaturePropertiesTimeExact: skip specification step b. Only fire a neuron if the last segment time is ideal (ie exact time expected for the last segment index). This is redundant, as it is necessarily true (as the neuron fires when the last segment is activated).
	This update is being applied because earlier segment times may be overwritten before the neuron fires thereby compromising their use in a final segment time array check (b).
- patch inferenceUseNeuronFeaturePropertiesTime (and inferenceUseNeuronFeaturePropertiesTimeExact) so seed-phase activation/time segment updates follow the same rules as prediction-phase updates.
- patch the node drawing path to stop collapsing to branch 0 when randomlyAssignBranches=True
- define !multipleDendriticBranches:randomlyAssignBranches = False
MANUAL; - update readme
- patch updateObservedColumnsVerbose - arrayIndexPropertiesPos use applySparseMaxUpdate (instead of replace)
- patch drawRelationTypes - execute getFeaturePosValue
- patch updateObservedColumnsVerbose - set replacePropertiesEnabled = arrayIndexPropertiesActivationCreate or arrayIndexPropertiesTimeCreate
MANUAL; - add graphs

---
v1h (Codex IDE GPT-5.2-Codex):
- add proto GIAANNproto1h1a - upgrade seed phase:
	The seed phase of inference is being upgraded to use exactly the same code and logic as the non-seed prediction phase of inference.
	I have moved the old GIAANNproto_predictionSeed.py independent seed implementation to archive. Please upgrade GIAANNproto_prediction.py:processConceptWordsInference() to perform seed by executing processColumnInferencePrediction(seedPhase=True). The only difference between the prediction phase and the seed phase is that in the seed phase the feature which is selected to fire is always the target feature (not the predicted feature) - ie inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures is always overridden to False during the seed phase.
	ensure that the seed phase does not execute standard selection or beam search selection. It fires its first seed token (target), calculates updated segments of network, then automatically selects the next seed token (target), etc - for each seed token. The seed phase is a subset of the prediction phase (controlled by seedPhase=True).
MANUAL; - update arrayIndexPropertiesEfficient: set arrayIndexPropertiesActivation/arrayIndexPropertiesTime to inference only
MANUAL; - remove option performRedundantCoalesce
- patch updateObservedColumnsVerbose():replacePropertiesEnabled context (and deprecate replacePropertiesEnabled)
- implement option drawDelimiters=True (drawDelimitersTrain/drawDelimitersInference) - draws deterministic and probabilistic ref set delimiters (in red and pink respectively). All other neurons are drawn in drawDefault colours (prime concept feature neurons in blue and all other feature neurons in turquoise). When drawDelimiters=True, also draw the (outgoing) external connections of delimiter neurons in delimiterColourDeterministic/delimiterColourProbabilistic (ie red/pink).
MANUAL; - update readme
- patch time indexing between seed and prediction (inferenceUseNeuronFeaturePropertiesTime)
MANUAL; - set numSeedTokensInference=8, inferenceUseNeuronFeaturePropertiesTimeExact, useSANIfeaturesAndColumns
MANUAL; - remove debugInferenceUseNeuronFeaturePropertiesTime, debugDrawRelationTypesTrain
- consolidate shared standard inference/beamsearch code to GIAANNproto_predictionConstraints.py
- update inferenceBeamSearch=False to use beamSearchSelectSingleStepFeature()
MANUAL; - disable inferenceBeamSearch
add option debugTerminateInferenceOnNoPredictionCandidatesAvailable=False 
MANUAL; - add option debugPrintTrainSequenceRaw
MANUAL; - add option debugPrintConfiguration
- add inferenceApplySequentialActivationSparse:applySequentialActivationSparse - switched the sequential-activation gating in inference to stay sparse so the global activation tensor is no longer densified.
MANUAL; - remove debugSANIfeaturesAndColumns, debugInferencePredictionActivationAccumulation
- remove white space from the start of sequences.
- add option pretrainCombineHyphenatedNouns - combine nouns with a "-" between them.
- update processArticle to remove all sequences with less than numSeedTokensInference+1 tokens.
- upgrade isTokenReferenceSetDelimiterDeterministic/isTokenReferenceSetDelimiterProbabilistic to use predetermined pos types (GIAANNproto_sequencePOS).
- upgrade isTokenReferenceSetDelimiterDeterministic/isTokenReferenceSetDelimiterProbabilistic to use lemma-based POS checks for delimiter detection.
MANUAL; - rename debugPrintConceptColumnsDelimitByPOSwarnings to debugTerminateOnConceptColumnsDelimitByPOSerror - always print processConceptWords concept columns delimit by POS errors.
MANUAL; - remove legacy column assignment code from getTokenConceptFeatureIndex().
- skip inference when noDelimiterDetectedBetweenConceptTokens detected (train already skipped).
- add option useGPUsparseStrict - enforce strict sparse device during transfer to/from dense tensors.
MANUAL; - set maxSequenceLength=80 to reduce max GPU memory during train.
MANUAL; - rename concept feature neuron to prime concept feature neuron (disambiguate with instance concept features).
 - add option inferenceOnlyRetainPredictedTargetObservedColumn - only load/evict one observed column per prediction step.
 - add option inferenceOnlyRetainPredictedTargetObservedColumnBeamSearch - only retain currently predicted targets during beam search (else retains all predicted targets during beam search). If inferenceOnlyRetainPredictedTargetObservedColumn=True and inferenceOnlyRetainPredictedTargetObservedColumnBeamSearch=False, it will clear all beam search targets after beam search is finished.

---
v1i (Codex IDE GPT-5.2-Codex):
- add proto GIAANNproto1i1a - remove support for deprecated features:
	MANUAL; - remove support for inferencePredictiveNetwork=True (predictive network)
	MANUAL; - remove support for inferenceTrainPredictiveNetworkAllSequences=True
	MANUAL; - remove support for inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures=False
	MANUAL; - remove support for conceptColumnsDelimitByConceptFeaturesStart=True/conceptColumnsDelimitByConceptFeaturesMid=True
	MANUAL; - remove support for kcDynamic=True
	MANUAL; - remove support for conceptColumnsDelimitByPOS=False
	MANUAL; - remove support for SANIconceptNeurons=True (SANI concept neurons)
	MANUAL; - remove support for useInhibitoryNeurons=True (inhibitory neurons)
- remove support for multiple prediction column/feature pairs
MANUAL; - remove option inferenceBeamSearchConceptColumns
MANUAL; - remove beamSearchPredictNextFeature():debugBeamSearchFallback (selectMostActiveFeature)
- patch inferenceOnlyRetainPredictedTargetObservedColumn for inferenceTrainFirstSequences=True
- rename lastSequenceInPrompt to inferenceSequenceInPrompt
MANUAL; - update beamSearchSelectSingleStepFeature/beamSearchPredictNextFeature to only return prediction targets
MANUAL; - disable redundant option predictionColumnsMustActivateConceptFeature
MANUAL; - remove option inferenceInvertNeuronActivationUponPrediction
MANUAL; - remove option inferenceBurstAllPredictionsOrTargetsInSequence
MANUAL; - add option datasetsLibrary4plus
MANUAL; - add option useSpacyForConceptNounPOSdetection=False - update isConcept() to use GIAANNproto_sequencePOS predetermined word-POS dictionaries for pos detection
- patch remove support for SANIconceptNeurons=True - reintroduce the missing conceptsFound guard so sequences with no concept tokens are skipped before building SequenceObservedColumns
- add option combineSparseUpdatesPerSequence - updateObservedColumnsEfficient combines sparse updates per sequence instead of per column (reduces calls to coalesce)
- add saveGlobalFeatureNeuronsRate - only save the globalFeatureNeurons every x sequences
- add option inferenceStrengthLookupCache - cache strength lookup during inference
- add option inferenceStrengthLookupBypass - bypass cache strength lookup during inference (when inferenceBeamSearch=False)
- update beam search to advance sequence-time indices per depth so time-based activation constraints and scoring reflect the simulated future steps, instead of reusing the same timestamp for every beam leve
- patch beam search failure by rejecting empty beam sequences and routing the "no candidates" case through the existing connectivity error handler (for inferenceSegmentActivationsBooleanFeatureSegmentsOnly=False)
MANUAL; - set numSeedTokensInference=12 - higher arrayNumberOfSegments increase inference performance (and increase RAM cost)
MANUAL; - set numberOfDendriticBranches=2 - high branch counts are not beneficial with randomlyAssignBranches=False (with respect to RAM cost)
- add option debugLimitFeatures - can be used to recover database for inference if run out of ram during training
MANUAL; - recommend CUDA 12.8+ for current generation Nvidia
- implement option useLocalDataset=True;
	1) downloads the wikipedia dataset files to folder datasetFolder (see datasetName and datasetCfg for specific version downloaded).
	2) loads these local dataset files on demand (no online streaming)
- implement option useLocalDatasetDownloadManual=True, which manually downloads the dataset files
- manually set the dataset cache folder name (processed_dataset_cache), instead of it being randomly generated (e.g. "default-edd5ee2c28550939")
- add option drawNetworkSaveFormatVector=True (for both drawNetworkDuringTrainSave and drawNetworkDuringInferenceSave), which saves the matplotlib network images in svg format rather than png format.
- implement option debugPrintTotalInferenceTokens=True - print total number of inference tokens in seed phase, prediction phase, and both phases (summed across all sequences) 
- add option useSANIfeaturesAndColumnsInternal:drawRelationTypesConnectionsFromSource - updated drawRelationTypes edge coloring to use the source feature neuron POS via getFeaturePosValue(...), instead of connection POS values (which can be invalid after segment/branch aggregation). Added per column setup for relationSegmentIndex (adjacent column vs last segment when useSANIcolumns) and retrieval of source feature neurons (sequence or observed/global).
MANUAL; -update readme - add GIAANN-paper-WIP
- add docs/ with Distributed Neural Computation blog post
- in useInference=True mode, if debugPrintTotalFeatures=True, print c and f at start
MANUAL; - remove deprecated transformerUseInputConnections
MANUAL; - rename drawNetworkDuringInferencePredict to drawNetworkDuringInference
- reimplemented inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures=False mode to drive next-column activation from targets and report top-1 accuracy across prediction and inference tokens.
- patch inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures=False - fix target-driven inference so sequences complete even when prediction candidates are missing by bypassing connected/delimiter constraints for target activation and emitting <no prediction> instead of exiting.
- implement option trainTestSet=True (where it is set to False by default). This will change the start position of the huggingface dataset loader - instead of starting at the first article in the dataset, it will start at some predefined trainTestSetArticleOffset [where trainTestSetArticleOffset=datasetLength*(1-testSetRatio)]. debugPrintTrainSequenceRaw=True can be used to copy the sequences into the new inference_prompt.txt test set.
- when useInference=True, do not load the huggingface dataset via loadWikipediaDataset (as the data is loaded from inference_prompt.txt file)
- implement option inferenceAddNewFeatures=True - add a controlled "expansion" phase [to support inference on test set when it contains concept columns/features that are not present in the train set]. Run a short additional training pass on the test set without updating connection strengths/permanence (only build missing columns/features), then run inference.
- if inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures=False, then never execute ensurePredictionStateAvailable:raisePredictionConnectivityError, as it is always using the target not the prediction as sequence input - during both the seed and target phase of inference.
- implement option enforceDirectConnectionsIgnoreSeed=True - ignore predictionEnsureConnectedToPreviousPrediction and ensurePredictionStateAvailable checks during the seed phase of inference.

---
v1j (Codex IDE GPT-5.3-Codex):
- add proto GIAANNproto1j1a - reduce inference VRAM (for useInference:useGPUsparse=True):
	- update GIAANNproto_sequenceObservedColumnsExcitation - skip dense SequenceObservedColumns arrays during inference when drawing is disabled to avoid large to_dense() allocations.
	- update GIAANNproto_databaseNetworkExcitation - store globalFeatureNeuronsBackup (and connections, if present) on CPU and restore to GPU only when needed. This removes the GPU-resident backup copy.
	- update GIAANNproto_main - wrap inference in pt.no_grad() to eliminate autograd allocations without triggering sparse inference-tensor version-counter errors.
	- add option runtimeReleaseGPUMemory - runtime GPU cleanup feature that executes releaseRuntimeGpuMemory(sequenceCount) after each processed sequence (processSequence)
	- update activation/time sparse slices locally and removing per-token full global sparse tensor rewrites
- update processColumnInferencePrediction() - split all marked sections into subfunctions
- make debugPrintInferenceTop1Accuracy independent of inferenceUseNextTokenPredictionsOrTargetsToActivateNextColumnFeatures
- patch processConceptWordsInference() so top-1 accounting is padded with zero-accuracy entries for any unprocessed seed/prediction tokens after premature termination
- add option datasetOscar
- patch inferenceBeamSearch indentation (inactive execution path)
- add fullstop to conceptColumnsDelimiterWordTypes (required for multisentencePredictions)
- update datasetOscar:testSetStartOffset
- add option trainStoreFeatureMapsGlobally - store feature maps once globally, not in every *_data.pkl (ensure database scales linearly with trained sequences)
- only ever execute saveData() dictionary saves if((sequenceCount + 1) % saveGlobalFeatureNeuronsRate == 0)
